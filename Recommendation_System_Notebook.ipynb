{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMl9CVbx6KCIY9SPQR+yTtw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bharathsanjai/sentiment-based-product-recommendation-system/blob/main/Recommendation_System_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem Statement\n",
        "\n",
        "The e-commerce business is quite popular today. Here, you do not need to take orders by going to each customer. A company launches its website to sell the items to the end consumer, and customers can order the products that they require from the same website. Famous examples of such e-commerce companies are Amazon, Flipkart, Myntra, Paytm and Snapdeal.\n",
        "\n",
        "\n",
        "\n",
        "Suppose you are working as a Machine Learning Engineer in an e-commerce company named 'Ebuss'. Ebuss has captured a huge market share in many fields, and it sells the products in various categories such as household essentials, books, personal care products, medicines, cosmetic items, beauty products, electrical appliances, kitchen and dining products and health care products.\n",
        "\n",
        "\n",
        "\n",
        "With the advancement in technology, it is imperative for Ebuss to grow quickly in the e-commerce market to become a major leader in the market because it has to compete with the likes of Amazon, Flipkart, etc., which are already market leaders."
      ],
      "metadata": {
        "id": "hAEnuOv8rzDT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Running on GPU\n",
        "\n",
        "import platform\n",
        "import tensorflow as tf\n",
        "\n",
        "print(\"Python version: \", platform.python_version())\n",
        "print(\"TensorFlow version: \", tf.__version__)\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "    print('GPU not found. Running on CPU.')\n",
        "else:\n",
        "    print('GPU found. Running on GPU.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_a84mPxrynd",
        "outputId": "fe0fd067-1403-4416-d357-14b467451d56"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python version:  3.10.12\n",
            "TensorFlow version:  2.15.0\n",
            "GPU found. Running on GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0OlKRRyrryB",
        "outputId": "a264820a-d352-4d70-95ad-902b24591b78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re, nltk, spacy, string\n",
        "import en_core_web_sm\n",
        "# nlp = en_core_web_sm.load()\n",
        "nlp = spacy.load('en_core_web_sm',  disable=[\"parser\", \"ner\"])\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from plotly.offline import plot\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import Counter\n",
        "import string\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# import spellchecker\n",
        "# from spellchecker import SpellChecker\n",
        "\n",
        "from textblob import TextBlob\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Import pickle to save and load the model\n",
        "import pickle\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "# from sklearn.metrics import plot_roc_curve\n",
        "\n",
        "# Importing LogisticRegression from sklearn\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Importing Random Forest Classifier from sklearn\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# importing libraries for XGBoost classifier\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "from sklearn.metrics.pairwise import pairwise_distances\n",
        "\n",
        "from pprint import pprint"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrqqms7asI1c",
        "outputId": "547c747e-843a-4805-d387-68c05a72250f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning:\n",
            "\n",
            "[W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting max rows and columns\n",
        "\n",
        "pd.set_option(\"display.max_columns\", 50)\n",
        "pd.set_option(\"display.max_rows\", 50)\n",
        "pd.set_option('display.max_colwidth', 300)\n",
        "pd.set_option(\"display.precision\", 2)"
      ],
      "metadata": {
        "id": "WUwjsIkbtkVn"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "q0Q2_ZfVukgT"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/My Drive/capstone/sample30.csv\")"
      ],
      "metadata": {
        "id": "OorANp36sQeI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEAj_GO_utR-",
        "outputId": "f5b59dad-c864-451f-cdd5-651b7e68e1b2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30000, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GhDHybepuyr_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}